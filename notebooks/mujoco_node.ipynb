{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import svg\n",
    "from svg.dx import SeqDx\n",
    "\n",
    "sns.set(style='whitegrid', font_scale=1.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c96352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('/home/fakoor/code/remote/shift_uncertainty_rl_lab/code')\n",
    "# from misc import buffer\n",
    "# import pickle as pkl\n",
    "\n",
    "# root_dir = '/home/fakoor/code/remote/shift_uncertainty_rl_lab/code/ck'\n",
    "# task = 'Hopper-v3'\n",
    "# agent = 'sac'\n",
    "# exp_name = 'test-tcap-500k'\n",
    "\n",
    "# sac_update_res = int(5)\n",
    "# sac_update_total = int(500)\n",
    "# subsample_ratio = 1.\n",
    "\n",
    "# ref_locs = [25, 300, 475]\n",
    "# num_seeds = 1\n",
    "\n",
    "# start = sac_update_res\n",
    "# stop = sac_update_total + sac_update_res\n",
    "# update_range = list(range(start, stop, sac_update_res))\n",
    "\n",
    "# time_capsules = []\n",
    "# for n_update in update_range:\n",
    "#     tcap_file = '_'.join([\n",
    "#         task.lower(),\n",
    "#         agent,\n",
    "#         exp_name\n",
    "#     ])\n",
    "#     tcap_path = os.path.join(root_dir, tcap_file, f'agent-tcap-{n_update}k.pkl')\n",
    "#     try:\n",
    "#         with open(tcap_path, 'rb') as f:\n",
    "#             time_capsules.append(pkl.load(f))\n",
    "#     except FileNotFoundError:\n",
    "#         pass\n",
    "\n",
    "    \n",
    "# train_subseq_len = 4\n",
    "# test_subseq_len = 4    \n",
    "\n",
    "# (train_x, train_u), (test_x, test_u) = buffer.buffers_to_dataset(\n",
    "#     [tcap['visit_buffer'] for tcap in time_capsules],\n",
    "#     train_subseq_len,\n",
    "#     test_subseq_len,\n",
    "#     subsample_ratio=1.\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0386f6a",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Hopper-v3'\n",
    "\n",
    "train_x = np.load(\"../data/HopperFull-v0_cl20_xdata.npy\")\n",
    "train_u = np.load(\"../data/HopperFull-v0_cl20_udata.npy\")\n",
    "\n",
    "test_x = np.load(\"../data/HopperFull-v0_episodes_xdata.npy\")\n",
    "test_u = np.load(\"../data/HopperFull-v0_episodes_udata.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd489cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, train_subseq_len, x_size = train_x.shape\n",
    "_, _, u_size = train_u.shape\n",
    "\n",
    "num_test, test_subseq_len, _ = test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_mean = train_x.reshape(-1, x_size).mean(0)\n",
    "x_std = np.clip(train_x.reshape(-1, x_size).std(0), a_min=1e-6, a_max=None)\n",
    "u_mean = train_u.reshape(-1, u_size).mean(0)\n",
    "u_std = np.clip(train_u.reshape(-1, u_size).std(0), a_min=1e-6, a_max=None)\n",
    "\n",
    "train_x = (train_x - x_mean) / x_std\n",
    "train_u = (train_u - u_mean) / u_std\n",
    "\n",
    "test_x = (test_x - x_mean) / x_std\n",
    "test_u = (test_u - u_mean) / u_std\n",
    "\n",
    "\n",
    "train_dataset = data_utils.TensorDataset(\n",
    "    torch.tensor(train_x).float(),\n",
    "    torch.tensor(train_u).float()\n",
    ")\n",
    "\n",
    "test_dataset = data_utils.TensorDataset(\n",
    "    torch.tensor(test_x).float(),\n",
    "    torch.tensor(test_u).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844814d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, enc_hidden_size, rec_hidden_size, dec_hidden_size,\n",
    "                 enc_depth, rec_depth, dec_depth):\n",
    "        super().__init__()\n",
    "        self.encoder = svg.utils.mlp(input_size, enc_hidden_size, rec_hidden_size, enc_depth)\n",
    "        self.recurrent = nn.GRU(rec_hidden_size, rec_hidden_size, num_layers=rec_depth)\n",
    "        self.decoder = svg.utils.mlp(rec_hidden_size, dec_hidden_size, output_size, dec_depth)\n",
    "        self.rec_hidden_size = rec_hidden_size\n",
    "        self.rec_depth = rec_depth\n",
    "        \n",
    "    def init_hidden_state(self, inputs):\n",
    "        assert inputs.dim() == 2\n",
    "        n_batch = inputs.size(0)\n",
    "        h = torch.zeros(self.rec_depth, n_batch, self.rec_hidden_size).to(inputs)\n",
    "        return h\n",
    "        \n",
    "    def forward(self, inputs, hidden_state):\n",
    "        assert inputs.dim() == 2\n",
    "        inputs_emb = self.encoder(inputs).unsqueeze(0)\n",
    "        outputs_emb, hidden_state = self.recurrent(inputs_emb, hidden_state)\n",
    "        outputs = self.decoder(outputs_emb.squeeze(0))\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        s_dim = 12,\n",
    "        a_dim = 3,\n",
    "        hidden_size = 256,\n",
    "        num_layers = 2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        chs = [s_dim + a_dim] + num_layers * [hidden_size]\n",
    "        linears = [nn.Linear(chs[i], chs[i + 1]) for i in range(num_layers)]\n",
    "        activations = [nn.Tanh() for i in range(num_layers)]\n",
    "        self.net = nn.Sequential(\n",
    "            *[val for pair in zip(linears, activations) for val in pair],\n",
    "            nn.Linear(chs[-1], s_dim),\n",
    "        )\n",
    "        \n",
    "    def dx(self, t, z):\n",
    "        diff = (self.ts - t).pow(2)[t >= self.ts]\n",
    "        neigh = self.ts[t >= self.ts][diff.argmin()]\n",
    "        u_t = self.u[neigh.item()]\n",
    "        dz_dt = self.net(torch.cat([z, u_t], axis=-1))\n",
    "        return dz_dt\n",
    "\n",
    "    def integrate(self, z0, u, ts, tol=1e-4, method=\"euler\"):\n",
    "        self.u = {t.item(): u_t for t, u_t in zip(ts, u.permute(1, 0, 2))}\n",
    "        self.ts = ts\n",
    "        \n",
    "        bs = z0.shape[0]\n",
    "#         odeint_options = dict(step_size=1e-3, interp='linear')\n",
    "        odeint_options = {}\n",
    "        zt = odeint(self.dx, z0.reshape(bs, -1), ts, rtol=tol, method=method, options=odeint_options)\n",
    "        zt = zt.permute(1, 0, 2)  # T x N x D -> N x T x D\n",
    "        return zt[:, 1:]\n",
    "    \n",
    "    def forward(self, z0, u, ts):\n",
    "        return self.integrate(z0, u, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecNODE(SeqDx):\n",
    "    def integrate(self, z0, u, ts, tol=1e-4, method=\"euler\"):\n",
    "        self.h = self.init_hidden_state(z0)\n",
    "        self.u = {t.item(): u_t for t, u_t in zip(ts, u.permute(1, 0, 2))}\n",
    "        self.ts = ts\n",
    "        \n",
    "        bs = z0.shape[0]\n",
    "#         odeint_options = dict(step_size=1e-3, interp='linear')\n",
    "        odeint_options = {}\n",
    "        zt = odeint(self.dx, z0.reshape(bs, -1), ts, rtol=tol, method=method, options=odeint_options)\n",
    "        zt = zt.permute(1, 0, 2)  # T x N x D -> N x T x D\n",
    "        return zt[:, 1:]\n",
    "    \n",
    "    def dx(self, t, x):\n",
    "        diff = (self.ts - t).pow(2)[t >= self.ts]\n",
    "        neigh = self.ts[t >= self.ts][diff.argmin()]\n",
    "        u_t = self.u[neigh.item()]\n",
    "        batch_size = u_t.size(0)\n",
    "        \n",
    "        x_u = torch.cat([x, u_t], dim=-1)\n",
    "        x_u_emb = self.xu_enc(x_u).unsqueeze(0)\n",
    "        if self.rec_num_layers > 0:\n",
    "            dx_dt_emb, self.h = self.rec(x_u_emb, self.h)\n",
    "        else:\n",
    "            dx_dt_emb = xu_emb\n",
    "        dx_dt_emb = dx_dt_emb.squeeze(0)\n",
    "        \n",
    "        dx_dt = self.x_dec(dx_dt_emb)\n",
    "        return dx_dt\n",
    "    \n",
    "    def forward(self, z0, u, ts):\n",
    "        return self.integrate(z0, u, ts)\n",
    "        \n",
    "    def unroll(self, x, us, detach_xt=False):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return [{'params': self.parameters(), 'weight_decay': 0.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPPNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.seq_model = RecurrentNetwork(*args, **kwargs)\n",
    "        self.dx_model = RecurrentNetwork(*args, **kwargs)\n",
    "        \n",
    "    def forward(self, x_0, u):\n",
    "        seq_hidden_state = self.seq_model.init_hidden_state(x_0)\n",
    "        dx_hidden_state = self.dx_model.init_hidden_state(x_0)\n",
    "        x_seq = x_dx = x_0\n",
    "        pred_x = []\n",
    "        for u_t in u:\n",
    "            seq_input = torch.cat((x_seq, u_t), dim=-1)\n",
    "            x_seq = self.seq_model(seq_input, seq_hidden_state)\n",
    "            \n",
    "            dx_input = torch.cat((x_dx, u_t), dim=-1)\n",
    "            x_dx = x_dx + self.dx_model(dx_input, dx_hidden_state)\n",
    "            \n",
    "            pred_x.append(torch.stack((x_seq, x_dx)))\n",
    "            \n",
    "        pred_x = torch.stack([x.mean(0) for x in pred_x])\n",
    "        return pred_x\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        groups = [\n",
    "            {'params': self.seq_model.parameters(), 'weight_decay': 0.},\n",
    "            {'params': self.dx_model.parameters(), 'weight_decay': 0.},\n",
    "        ]\n",
    "        return groups\n",
    "    \n",
    "    \n",
    "class AutoregNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.seq_model = RecurrentNetwork(*args, **kwargs)\n",
    "        \n",
    "    def forward(self, x_0, u):\n",
    "        hidden_state = self.seq_model.init_hidden_state(x_0)\n",
    "        x_t = x_0\n",
    "        pred_x = []\n",
    "        for u_t in u:\n",
    "            x_u = torch.cat((x_t, u_t), dim=-1)\n",
    "            x_t = self.seq_model(x_u, hidden_state)\n",
    "            pred_x.append(x_t)\n",
    "        return torch.stack(pred_x)\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return [{'params': self.parameters(), 'weight_decay': 0.}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d95f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = (1. / train_x.shape[1]) * torch.arange(train_x.shape[1])\n",
    "time_step = 1.\n",
    "train_ts = torch.tensor(\n",
    "    np.linspace(0, time_step*(train_subseq_len), train_subseq_len + 1)\n",
    ").float().to('cuda:0')\n",
    "test_ts = torch.tensor(\n",
    "    np.linspace(0, time_step*(test_subseq_len), test_subseq_len + 1)\n",
    ").float().to('cuda:0')\n",
    "\n",
    "# s_dim, a_dim = x.shape[-1], u.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_net(net, train_loader, test_loader, num_epochs):\n",
    "    optimizer = optim.Adam(net.param_groups, lr=1e-3)\n",
    "    lr_sched = optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-6, T_max=num_epochs)\n",
    "\n",
    "    records = []\n",
    "    for _ in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        for x, u in train_loader:\n",
    "            x, u = x.to('cuda:0'), u.to('cuda:0')\n",
    "            \n",
    "            args = [u, train_ts] if hasattr(net, 'integrate') else [u.permute(1, 0, 2)] \n",
    "            z_pred = net(x[:,0], *args)\n",
    "            z_pred = z_pred if hasattr(net, 'integrate') else z_pred.permute(1, 0, 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = (z_pred[:, :-1] - x[:, 1:]).pow(2).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "        lr_sched.step()\n",
    "\n",
    "        test_mse, test_med_se = 0., 0.\n",
    "        for x, u in test_loader:\n",
    "            x, u = x.to('cuda:0'), u.to('cuda:0')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                args = [u, test_ts] if hasattr(net, 'integrate') else [u.permute(1, 0, 2)] \n",
    "                z_pred = net(x[:,0], *args)\n",
    "                z_pred = z_pred if hasattr(net, 'integrate') else z_pred.permute(1, 0, 2)\n",
    "                \n",
    "            test_se = (z_pred[:, :-1] - x[:, 1:]).pow(2).mean(0).mean(-1)\n",
    "            test_mse += test_se.mean().item() / len(test_loader)\n",
    "            test_med_se += test_se.median().item() / len(test_loader)\n",
    "\n",
    "        records.append(dict(train_mse=avg_loss, test_mse=test_mse, test_med_se=test_med_se))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_loader = data_utils.DataLoader(train_dataset, 200)\n",
    "test_loader = data_utils.DataLoader(test_dataset, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ebd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpp_net_config = dict(\n",
    "    input_size=(x_size + u_size),\n",
    "    output_size=x_size,\n",
    "    enc_hidden_size=512,\n",
    "    rec_hidden_size=512,\n",
    "    dec_hidden_size=512,\n",
    "    enc_depth=2,\n",
    "    rec_depth=2,\n",
    "    dec_depth=0\n",
    ")\n",
    "rpp_net = RPPNet(**rpp_net_config).to('cuda')\n",
    "rpp_records = fit_net(rpp_net, train_loader, test_loader, num_epochs)\n",
    "rpp_df = pd.DataFrame(rpp_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreg_net_config = dict(\n",
    "    input_size=(x_size + u_size),\n",
    "    output_size=x_size,\n",
    "    enc_hidden_size=512,\n",
    "    rec_hidden_size=512,\n",
    "    dec_hidden_size=512,\n",
    "    enc_depth=2,\n",
    "    rec_depth=2,\n",
    "    dec_depth=0\n",
    ")\n",
    "autoreg_net = AutoregNet(**autoreg_net_config).to('cuda')\n",
    "autoreg_records = fit_net(autoreg_net, train_loader, test_loader, num_epochs)\n",
    "autoreg_df = pd.DataFrame(autoreg_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfdc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_net_config = dict(\n",
    "    env_name=task,\n",
    "    obs_dim=x_size,\n",
    "    action_dim=u_size,\n",
    "    action_range=None,\n",
    "    horizon=4,\n",
    "    device='cuda',\n",
    "    detach_xt=False,\n",
    "    xu_enc_hidden_dim=512,\n",
    "    xu_enc_hidden_depth=2,\n",
    "    x_dec_hidden_dim=512,\n",
    "    x_dec_hidden_depth=0,\n",
    "    clip_grad_norm=1.0,\n",
    "    rec_type='GRU',\n",
    "    rec_latent_dim=512,\n",
    "    rec_num_layers=2,\n",
    "    lr=1e-3,\n",
    ")\n",
    "# rec_net = SeqDx(**rec_net_config).to('cuda')\n",
    "\n",
    "# rec_net_records = fit_net(rec_net, train_loader, test_loader, num_epochs)\n",
    "# rec_net_df = pd.DataFrame(rec_net_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_node_config = copy.deepcopy(rec_net_config)\n",
    "rec_node = RecNODE(**rec_node_config).to('cuda')\n",
    "\n",
    "rec_node_records = fit_net(rec_node, train_loader, test_loader, num_epochs)\n",
    "rec_node_df = pd.DataFrame(rec_node_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ce84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_node = NN(x_size, u_size, hidden_size=512, num_layers=4).to('cuda:0')\n",
    "# mlp_node_records = fit_net(mlp_node, train_loader, test_loader, num_epochs)\n",
    "# mlp_node_df = pd.DataFrame(mlp_node_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rec_net_df.train_mse, label='GRU-Delta')\n",
    "plt.plot(rec_node_df.train_mse, label='NODE (Euler)')\n",
    "# plt.plot(mlp_node_df.train_mse, label='MLP-NODE (Euler)')\n",
    "plt.plot(autoreg_df.train_mse, label='Seq.')\n",
    "plt.plot(rpp_df.train_mse, label='RPP')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Train MSE')\n",
    "plt.title(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(rec_net_df.test_mse, label='GRU-Delta')\n",
    "plt.plot(rec_node_df.test_med_se, label='NODE')\n",
    "# plt.plot(mlp_node_df.test_med_se, label='MLP-NODE')\n",
    "plt.plot(autoreg_df.test_med_se, label='Seq.')\n",
    "plt.plot(rpp_df.test_med_se, label='RPP')\n",
    "# plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Test Median SE')\n",
    "plt.title(task)\n",
    "# plt.yscale('log')\n",
    "plt.ylim(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386671ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
